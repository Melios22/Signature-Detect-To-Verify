{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import neccesary libraries and define global constants\n___","metadata":{}},{"cell_type":"code","source":"# --- Import Libraries ---\n# Standard/Data handling libraries\nimport os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import confusion_matrix\n\n# ML/DL utilities and framework (PyTorch, torchvision)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import RMSprop, AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import transforms as T\n\n# Process image\nfrom PIL import Image\n\n# --- Device Setup ---\n# Set device to GPU ('cuda') if available, otherwise use CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    print(f'Using GPU')\nelse:\n    print(f'Using CPU')\n\n# Define dataset path and training parameters\nIMG_SIZE = (105, 105) # Image size for preprocessing \nBATCH_SIZE = 32 # Number of samples per batch","metadata":{"_uuid":"da3bcb22-8642-41f1-95de-3ebcb4af4d85","_cell_guid":"d1533013-f4d9-4d8d-a55e-449c3d6b4de9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Support functions\nHere we define some functions with purpose of ploting during and after training, calculate the distances and simulate the testing step of accuracies","metadata":{}},{"cell_type":"code","source":"def collect_distances(model, data_loader):\n        \"\"\"Calculate the distances\"\"\"\n        model.eval()\n        all_distances = []\n        all_labels = []\n    \n        # Calculate the the distance without update the weights\n        with torch.no_grad():\n            for (img0, img1), labels in tqdm(data_loader, desc=\"Collecting distances\", dynamic_ncols=True):\n                img0, img1 = img0.to(model.device), img1.to(model.device)\n                output1, output2 = model(img0, img1)\n\n                # Compute the Euclidean distances\n                distances = F.pairwise_distance(output1, output2)\n                all_distances.extend(distances.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n        return np.array(all_distances), np.array(all_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_distance_distribution(model, data_loader, flag, epoch = 0, threshold=None):\n    \"\"\"Plot the distribution of the instances with a threshold line.\"\"\"\n    distances, labels = collect_distances(model, data_loader)\n    \n    # Convert distances to numpy array and handle infinities\n    distances = np.asarray(distances)\n    distances = np.where(np.isinf(distances), np.nan, distances)\n    \n    plt.figure(figsize=(10, 6))\n    \n    # Plot histograms, ignoring NaN values\n    sns.histplot(distances[labels == 0], color='green', label='Genuine Pairs', kde=False, bins=40, stat='probability')\n    sns.histplot(distances[labels == 1], color='red', label='Forged Pairs', kde=False, bins=40, stat='probability')\n\n    # Add a vertical line for the threshold\n    if threshold is not None:\n        plt.axvline(threshold, color='black', linestyle='dashed', linewidth=2, label=f'Threshold = {threshold:.3f}')\n    \n    # Labels and title\n    plt.xlabel(\"Euclidean Distance\")\n    plt.ylabel(\"Ratio\")\n    plt.yscale('log')  # Compress tall peaks\n    plt.yticks([])  # removes y-axis ticks\n    plt.ylabel('')  # removes y-axis label (optional)\n\n    title = f'Train Distance Distribution after Epoch {epoch}' if flag == 0 else \"Test Distance Distribution\"\n    filename = f\"Train_Distance_Distribution_Epoch_{epoch}.png\" if flag == 0 else \"Test_Distance_Distribution.png\"\n\n    plt.title(title)\n    plt.legend()\n\n    # Save and show the plot\n    plt.savefig(filename, dpi=300, bbox_inches='tight')  # Save as PNG with high resolution\n    plt.show()\n    plt.close()  # Close the figure to free memory\n\n\ndef plot_loss_accu(history, filename=\"training_overtime.png\"):\n    \"\"\" Plot the change in loss and accuracy while training.\"\"\"\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, len(history['train_loss']) + 1), history['train_loss'], marker='o', label='Train Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, len(history['train_acc']) + 1), history['train_acc'], marker='o', label='Train Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Training Accuracy')\n    plt.legend()\n\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    plt.show()\n    plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Get the Dataset from HUB and prepare it for model training","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass SiameseHFDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.dataset = hf_dataset\n        self.transform = T.Compose([\n            T.Grayscale(),\n            T.Resize(IMG_SIZE),\n            T.ToTensor(),\n            T.Normalize(mean=[0.5], std=[0.5]),\n        ])\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n\n        # Load and transform both images\n        img1 = item['to_verify_signature'] if isinstance(item['to_verify_signature'], Image.Image) else Image.open(item['to_verify_signature']).convert(\"RGB\")\n        img2 = item['sample_signature'] if isinstance(item['sample_signature'], Image.Image) else Image.open(item['sample_signature']).convert(\"RGB\")\n\n        img1 = self.transform(img1)\n        img2 = self.transform(img2)\n\n        return (img1, img2), torch.tensor(item['label'], dtype=torch.float32)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you have a loaded HF dataset like `hf_dataset`\n\nfrom datasets import load_dataset\ndata_loader = load_dataset(\"Mels22/signature_detection_verification\")\n\nwrapped_dataset_train = SiameseHFDataset(data_loader['train'])\ntrain_loader = DataLoader(\n    wrapped_dataset_train,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4, # Use 4 background processes for data loading\n    persistent_workers=True  # Keep worker processes alive between epochs\n)\n\nwrapped_dataset_test = SiameseHFDataset(data_loader['test'])\ntest_loader = DataLoader(\n    wrapped_dataset_test,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4, # Use 4 background processes for data loading\n    persistent_workers=True  # Keep worker processes alive between epochs\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Define the Contrastive Loss function","metadata":{}},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    \"\"\"\n    Contrastive loss function for similarity learning.\n    This loss function is particularly useful when training models to learn embeddings\n    where similar pairs of inputs are mapped close together in the embedding space,\n    and dissimilar pairs are mapped far apart.\n    \"\"\"\n    def __init__(self, margin=1.5):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        \"\"\"Compute contrastive loss using Euclidean Distance.\"\"\"\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean(\n            (1 - label) * torch.pow(euclidean_distance, 2) +\n            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n        )\n            \n        return loss_contrastive","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Define the Siamese Network, with updated layers to reduce the parameter count\nOn the old version, the siamese network consisted of these blocks of CNN and FC:\n```python\nself.cnn = nn.Sequential(\n    # First Conv Layer\n    nn.Conv2d(1, 64, kernel_size=10),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    # Second Conv Layer\n    nn.Conv2d(64, 128, kernel_size=7),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    # Third Conv Layer\n    nn.Conv2d(128, 128, kernel_size=4),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    # Fourth Layer\n    nn.Conv2d(128, 256, kernel_size=4),\n    nn.ReLU(),\n    nn.Flatten()\n)\nself.fc = nn.Sequential(\n    nn.Linear(9216, 4096),\n    nn.ReLU(),\n    nn.Linear(4096, embedding_size),\n)\n```","metadata":{}},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    \"\"\"Siamese network for signature verification.\"\"\"\n    def __init__(self, device=None, lr=1e-4, from_file=None, embedding_size=256):\n        \"\"\"\n        Initializes the SignatureRCNN model.\n\n        Args:\n            device (torch.device, optional): Device to use for computation (CPU or CUDA). Defaults to CUDA if available, otherwise CPU.\n            lr (float, optional): Learning rate for the optimizer. Defaults to 1e-4.\n            from_file (str, optional): Path to a pre-trained model file to load. Defaults to None.\n            embedding_size (int): Size of the final feature vector.\n        \"\"\"\n        super(SiameseNetwork, self).__init__()\n        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        # Define convolutional layers for feature extraction\n        self.cnn = nn.Sequential(\n            # Block 1: 1 input channel (grayscale), 64 output channels\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.LeakyReLU(), # Replace ReLU\n            nn.BatchNorm2d(64), # Add BatchNorm to stabalize\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), # Stride=2 for downsampling, (replaces MaxPool)\n\n            # Block 2: 64 input channels, 128 output channels\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.LeakyReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n\n            # Block 3: 128 input channels, 256 output channels\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.LeakyReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n\n            # Block 4: 256 input channels, 512 output channels\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.LeakyReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n            \n            nn.AdaptiveAvgPool2d((1, 1)) # Replace flattening, less overfit, more intepretable features\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, embedding_size)\n        )\n        \n        # Set up optimizer and criterion\n        self.criterion = ContrastiveLoss(margin=1.5)\n        self.optimizer = AdamW(self.parameters(), lr=lr, weight_decay=1e-4)\n\n        # Load the model weight if exist\n        if from_file and os.path.exists(from_file):\n            self.load_from_file(from_file)   \n        self.to(self.device)\n     \n    def forward_once(self, x):\n        \"\"\"Pass input through the feature extractor.\"\"\" \n        output = self.cnn(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc(output)\n        return output\n\n    def forward(self, input1, input2):\n        \"\"\"Compute embeddings for both images in the pair.\"\"\"\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2\n\n    def load_from_file(self, file_path):\n        \"\"\"Load the model weights from a pre-trained file\"\"\"\n        checkpoint = torch.load(file_path, map_location=self.device, weights_only=True)\n        self.cnn.load_state_dict(checkpoint['cnn'])\n        self.fc.load_state_dict(checkpoint['fc'])\n        print(f\"Loaded weights from {file_path}\")\n\n    def save_to_file(self, file_path):\n        \"\"\"Save the model weights\"\"\"\n        torch.save({\n            'cnn': self.cnn.state_dict(),\n            'fc': self.fc.state_dict()\n        }, file_path)\n        print(\"Saved the new model\")\n    \n    def compute_accuracy(self, output1, output2, labels, threshold=0.5):\n        \"\"\"Compute accuracy based on Euclidean distance threshold.\"\"\"\n        distances = F.pairwise_distance(output1, output2)\n        predictions = (distances > threshold).float()\n        correct = (predictions == labels).sum().item()\n        return correct, len(labels)\n    \n    def train_one_epoch(self, train_loader, epoch_count, total_epoch=None):\n        \"\"\" Iterate through the training data to update weight \"\"\"\n        self.train()\n        epoch_train_loss = 0.0     # loss after each epoch\n        train_correct = 0          # number of correct samples\n        total_train_samples = 0    # total number of samples\n        \n        for (img0, img1), label in tqdm(train_loader, desc=f\"[Train] Epoch {epoch_count} / {total_epoch}\", dynamic_ncols=True):\n            # Move images and labels to the appropriate device (GPU/CPU)\n            img0, img1, label = img0.to(self.device), img1.to(self.device), label.to(self.device)\n            self.optimizer.zero_grad() # Reset gradients\n            output1, output2 = self(img0, img1) # Forward pass\n            \n            loss_contrastive = self.criterion(output1, output2, label) # Calculate loss function\n            loss_contrastive.backward() # Backpropagation\n            self.optimizer.step() # Update model parameters\n            # After update weights\n            epoch_train_loss += loss_contrastive.item()   # Accumulate loss\n            correct, total = self.compute_accuracy(output1, output2, label)  # Compute accuracy\n            train_correct += correct \n            total_train_samples += total\n\n        # Calculate average loss and training accuracy\n        avg_train_loss = epoch_train_loss / len(train_loader)\n        train_accuracy = train_correct / total_train_samples\n        return avg_train_loss, train_accuracy\n\n    def train_model(self, train_loader, epochs=25, file_path=\"Siamese_savefile.pth\", plot_every=5):\n        \"\"\" Iterate through all epochs to update weight \"\"\"\n        # Learning rate scheduler to adjust learning rate based on validation loss\n        scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6)\n        # Dictionary to store training history\n        history = {'train_loss': [], 'train_acc': [], 'lr': []}\n\n        for epoch in range(1, epochs+1):\n            # Train for one epoch\n            avg_train_loss, train_accuracy = self.train_one_epoch(train_loader, epoch, epochs)\n            history['train_loss'].append(avg_train_loss)\n            history['train_acc'].append(train_accuracy)\n\n            # Update learning rate based on loss\n            scheduler.step(avg_train_loss)\n            current_lr = self.optimizer.param_groups[0]['lr']\n            history['lr'].append(current_lr)\n\n            # Print epoch summary\n            print(f\"Epoch [{epoch}/{epochs}] - Train Loss: {avg_train_loss:.6f}, Train Acc: {train_accuracy:.4f}, LR: {current_lr:.6f}\")\n\n            # Plot the distribution of Euclidean distances on Train set\n            if plot_every != -1:\n                if (epoch-1) % plot_every == 0 and epoch != 1:\n                    plot_distance_distribution(self, train_loader, 0, epoch)\n\n            else:\n                if epoch == epochs - 1:\n                    plot_distance_distribution(self, train_loader, 0, epoch)\n                \n        # Plot training loss and accuracy over epochs\n        plot_loss_accu(history)    \n        self.save_to_file(file_path) # Save the model after trained\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize and training the model\nmodel = SiameseNetwork(embedding_size=256)\n# model = SiameseNetwork(embedding_size=256, from_file='the-old-model.pt')\n\nepochs = 15\nmodel_save_path = 'latest_siamese_1.pt'\nmodel.train_model(train_loader, epochs=epochs, file_path=model_save_path, plot_every=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Define the function to evaluate and logged out the error cases","metadata":{}},{"cell_type":"code","source":"def evaluate_and_log_errors(model, data_loader, threshold=0.5):\n    \"\"\"Evaluates the Siamese Network and logs misclassified samples.\"\"\"\n    model.eval()\n    true_labels = []\n    pred_labels = []\n    misclassified_samples = []\n    \n    all_distances = []\n    all_labels = []\n    \n    with torch.no_grad():  # Disable gradient computation\n        for (img0, img1), labels in tqdm(data_loader, desc=\"Evaluating\", dynamic_ncols=True):\n            img0, img1 = img0.to(model.device), img1.to(model.device)\n            output1, output2 = model(img0, img1)\n\n            # Compute Euclidean distance\n            distances = F.pairwise_distance(output1, output2)\n\n            all_distances.extend(distances.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            predictions = (distances > threshold).float()\n            \n            true_labels.extend(labels.cpu().numpy())\n            pred_labels.extend(predictions.cpu().numpy())\n\n            # Log misclassified cases\n            for i in range(len(labels)):\n                if labels[i].item() != predictions[i].item():\n                    misclassified_samples.append((img0[i].cpu(), img1[i].cpu(), labels[i].item(), predictions[i].item()))\n\n    \"\"\" Plot Distribution of Euclidean distances on Test set\"\"\"\n    distances, labels = np.array(all_distances), np.array(all_labels)\n    # Compute confusion matrix\n\n    distances = np.asarray(distances)\n    distances = np.where(np.isinf(distances), np.nan, distances)\n    \n    plt.figure(figsize=(10, 6))\n\n    # Plot histograms, ignoring NaN values\n    sns.histplot(distances[labels == 0], color='green', label='Genuine Pairs', kde=True, bins=40, stat='probability')\n    sns.histplot(distances[labels == 1], color='red', label='Forged Pairs', kde=True, bins=40, stat='probability')\n\n    # Add a vertical line for the threshold\n    if threshold is not None:\n        plt.axvline(threshold, color='black', linestyle='dashed', linewidth=2, label=f'Threshold = {threshold:.3f}')\n\n    # Labels and title\n    plt.xlabel(\"Euclidean Distance\")\n    plt.ylabel(\"Ratio\")\n    plt.yscale('log')  # Compress tall peaks\n    plt.yticks([])  # removes y-axis ticks\n    plt.ylabel('')  # removes y-axis label (optional)\n\n    title = \"Test Distance Distribution\"\n    filename = \"Test_Distance_Distribution.png\"\n\n    plt.title(title)\n    plt.legend()\n\n    # Save and show the plot\n    plt.savefig(filename, dpi=300, bbox_inches='tight')  # Save as PNG with high resolution\n    plt.show()\n\n    \"\"\" Plot confusion matrix \"\"\" \n    cm = confusion_matrix(true_labels, pred_labels)\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Genuine\", \"Forged\"], yticklabels=[\"Genuine\", \"Forged\"])\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix for Signature Verification\")\n    # plt.savefig(\"cm.png\", dpi = 300, bbox_inches='tight')\n    plt.show()\n\n    print(f\"Number of misclassified samples: {len(misclassified_samples)}\")\n    \n    # Save or display the misclassified samples\n    return misclassified_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot out the misclassified images","metadata":{}},{"cell_type":"code","source":"# Run function and retrieve misclassified samples\nmisclassified_samples = evaluate_and_log_errors(model, test_loader, threshold=0.5)\n\n# Display the misclassified image pair\nfor idx, (img0, img1, true_label, pred_label) in enumerate(misclassified_samples[:10]):\n    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n\n    # Convert labels to meaningful text\n    true_label_text = \"Genuine\" if true_label == 0 else \"Forged\"\n    pred_label_text = \"Genuine\" if pred_label == 0 else \"Forged\"\n    # Plot first image\n    axes[0].imshow(img0.squeeze(), cmap=\"gray\")\n    axes[0].set_title(f\"True Label: {true_label_text}\")\n    # Plot second image\n    axes[1].imshow(img1.squeeze(), cmap=\"gray\")\n    axes[1].set_title(f\"Predicted Label: {pred_label_text}\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___\n# Option: Push the model to Hugging Face","metadata":{}},{"cell_type":"code","source":"# from huggingface_hub import HfApi\n# HF_TOKEN = \"YOUR-HF-TOKEN\"\n\n# api = HfApi(token=HF_TOKEN)\n# api.upload_folder(\n#     folder_path=model_save_path,\n#     repo_id=\"Mels22/Signature-Detection-Verification\",\n#     repo_type=\"model\",\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}